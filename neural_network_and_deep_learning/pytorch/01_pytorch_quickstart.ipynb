{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = training_data[0]  # 0th image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the training dataset 60000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Length of the training dataset {len(training_data)}\")\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_np = image.squeeze(dim=0).numpy()\n",
    "plt.imshow(image_np, cmap=\"gray\")\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.25, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten(start_dim =1)\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(f\"Size of input Tensor {x.shape}\")\n",
    "        x = self.flatten(x)\n",
    "        #print(f\"After Flatten: {x.shape}\")\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.298296  [   64/60000]\n",
      "loss: 2.282213  [ 6464/60000]\n",
      "loss: 2.266148  [12864/60000]\n",
      "loss: 2.263077  [19264/60000]\n",
      "loss: 2.268831  [25664/60000]\n",
      "loss: 2.225084  [32064/60000]\n",
      "loss: 2.245842  [38464/60000]\n",
      "loss: 2.199167  [44864/60000]\n",
      "loss: 2.205921  [51264/60000]\n",
      "loss: 2.186027  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 36.4%, Avg loss: 2.163777 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.181344  [   64/60000]\n",
      "loss: 2.166702  [ 6464/60000]\n",
      "loss: 2.114061  [12864/60000]\n",
      "loss: 2.139325  [19264/60000]\n",
      "loss: 2.099915  [25664/60000]\n",
      "loss: 2.035254  [32064/60000]\n",
      "loss: 2.087618  [38464/60000]\n",
      "loss: 2.000578  [44864/60000]\n",
      "loss: 2.002508  [51264/60000]\n",
      "loss: 1.950973  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 1.915715 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.960988  [   64/60000]\n",
      "loss: 1.924359  [ 6464/60000]\n",
      "loss: 1.854146  [12864/60000]\n",
      "loss: 1.860061  [19264/60000]\n",
      "loss: 1.766131  [25664/60000]\n",
      "loss: 1.724658  [32064/60000]\n",
      "loss: 1.747804  [38464/60000]\n",
      "loss: 1.640125  [44864/60000]\n",
      "loss: 1.671738  [51264/60000]\n",
      "loss: 1.570330  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.6%, Avg loss: 1.545847 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.631749  [   64/60000]\n",
      "loss: 1.592189  [ 6464/60000]\n",
      "loss: 1.474233  [12864/60000]\n",
      "loss: 1.525604  [19264/60000]\n",
      "loss: 1.430795  [25664/60000]\n",
      "loss: 1.385079  [32064/60000]\n",
      "loss: 1.415063  [38464/60000]\n",
      "loss: 1.330629  [44864/60000]\n",
      "loss: 1.366863  [51264/60000]\n",
      "loss: 1.258173  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 1.265006 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.375588  [   64/60000]\n",
      "loss: 1.334530  [ 6464/60000]\n",
      "loss: 1.181517  [12864/60000]\n",
      "loss: 1.300183  [19264/60000]\n",
      "loss: 1.192963  [25664/60000]\n",
      "loss: 1.189192  [32064/60000]\n",
      "loss: 1.233815  [38464/60000]\n",
      "loss: 1.134293  [44864/60000]\n",
      "loss: 1.197205  [51264/60000]\n",
      "loss: 1.101940  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.7%, Avg loss: 1.092474 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.196014  [   64/60000]\n",
      "loss: 1.213762  [ 6464/60000]\n",
      "loss: 1.018933  [12864/60000]\n",
      "loss: 1.146462  [19264/60000]\n",
      "loss: 1.021540  [25664/60000]\n",
      "loss: 1.032592  [32064/60000]\n",
      "loss: 1.116143  [38464/60000]\n",
      "loss: 1.023080  [44864/60000]\n",
      "loss: 1.052058  [51264/60000]\n",
      "loss: 1.003589  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.983323 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.081786  [   64/60000]\n",
      "loss: 1.118868  [ 6464/60000]\n",
      "loss: 0.879458  [12864/60000]\n",
      "loss: 1.042356  [19264/60000]\n",
      "loss: 0.893699  [25664/60000]\n",
      "loss: 0.976261  [32064/60000]\n",
      "loss: 0.957645  [38464/60000]\n",
      "loss: 0.950382  [44864/60000]\n",
      "loss: 0.975640  [51264/60000]\n",
      "loss: 0.922089  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 0.910578 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.970003  [   64/60000]\n",
      "loss: 1.023136  [ 6464/60000]\n",
      "loss: 0.825816  [12864/60000]\n",
      "loss: 1.031218  [19264/60000]\n",
      "loss: 0.866112  [25664/60000]\n",
      "loss: 0.855157  [32064/60000]\n",
      "loss: 0.955455  [38464/60000]\n",
      "loss: 0.937556  [44864/60000]\n",
      "loss: 0.965490  [51264/60000]\n",
      "loss: 0.880244  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.859537 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.901527  [   64/60000]\n",
      "loss: 0.990419  [ 6464/60000]\n",
      "loss: 0.742971  [12864/60000]\n",
      "loss: 0.980194  [19264/60000]\n",
      "loss: 0.843835  [25664/60000]\n",
      "loss: 0.854469  [32064/60000]\n",
      "loss: 0.946432  [38464/60000]\n",
      "loss: 0.901446  [44864/60000]\n",
      "loss: 0.880539  [51264/60000]\n",
      "loss: 0.808153  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.821849 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.853238  [   64/60000]\n",
      "loss: 0.932680  [ 6464/60000]\n",
      "loss: 0.702776  [12864/60000]\n",
      "loss: 0.933771  [19264/60000]\n",
      "loss: 0.807236  [25664/60000]\n",
      "loss: 0.803624  [32064/60000]\n",
      "loss: 0.906728  [38464/60000]\n",
      "loss: 0.864268  [44864/60000]\n",
      "loss: 0.856516  [51264/60000]\n",
      "loss: 0.805792  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.792234 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.813779  [   64/60000]\n",
      "loss: 0.863903  [ 6464/60000]\n",
      "loss: 0.668801  [12864/60000]\n",
      "loss: 0.878438  [19264/60000]\n",
      "loss: 0.772139  [25664/60000]\n",
      "loss: 0.773446  [32064/60000]\n",
      "loss: 0.852162  [38464/60000]\n",
      "loss: 0.880208  [44864/60000]\n",
      "loss: 0.793738  [51264/60000]\n",
      "loss: 0.768993  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 0.767975 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.770365  [   64/60000]\n",
      "loss: 0.865316  [ 6464/60000]\n",
      "loss: 0.666259  [12864/60000]\n",
      "loss: 0.812501  [19264/60000]\n",
      "loss: 0.768294  [25664/60000]\n",
      "loss: 0.754508  [32064/60000]\n",
      "loss: 0.829981  [38464/60000]\n",
      "loss: 0.821262  [44864/60000]\n",
      "loss: 0.800309  [51264/60000]\n",
      "loss: 0.740091  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.747186 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.789585  [   64/60000]\n",
      "loss: 0.819980  [ 6464/60000]\n",
      "loss: 0.597671  [12864/60000]\n",
      "loss: 0.799215  [19264/60000]\n",
      "loss: 0.749160  [25664/60000]\n",
      "loss: 0.727265  [32064/60000]\n",
      "loss: 0.790014  [38464/60000]\n",
      "loss: 0.760097  [44864/60000]\n",
      "loss: 0.831657  [51264/60000]\n",
      "loss: 0.712645  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.728866 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.717295  [   64/60000]\n",
      "loss: 0.801778  [ 6464/60000]\n",
      "loss: 0.598143  [12864/60000]\n",
      "loss: 0.837110  [19264/60000]\n",
      "loss: 0.731961  [25664/60000]\n",
      "loss: 0.732344  [32064/60000]\n",
      "loss: 0.779369  [38464/60000]\n",
      "loss: 0.739902  [44864/60000]\n",
      "loss: 0.755351  [51264/60000]\n",
      "loss: 0.701263  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.712342 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.678608  [   64/60000]\n",
      "loss: 0.835714  [ 6464/60000]\n",
      "loss: 0.556177  [12864/60000]\n",
      "loss: 0.771743  [19264/60000]\n",
      "loss: 0.705848  [25664/60000]\n",
      "loss: 0.681211  [32064/60000]\n",
      "loss: 0.783069  [38464/60000]\n",
      "loss: 0.795003  [44864/60000]\n",
      "loss: 0.758296  [51264/60000]\n",
      "loss: 0.740307  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.697342 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.683619  [   64/60000]\n",
      "loss: 0.755973  [ 6464/60000]\n",
      "loss: 0.554527  [12864/60000]\n",
      "loss: 0.758081  [19264/60000]\n",
      "loss: 0.698933  [25664/60000]\n",
      "loss: 0.674997  [32064/60000]\n",
      "loss: 0.804926  [38464/60000]\n",
      "loss: 0.721176  [44864/60000]\n",
      "loss: 0.765750  [51264/60000]\n",
      "loss: 0.683950  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.683126 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.674869  [   64/60000]\n",
      "loss: 0.768249  [ 6464/60000]\n",
      "loss: 0.535483  [12864/60000]\n",
      "loss: 0.752313  [19264/60000]\n",
      "loss: 0.707287  [25664/60000]\n",
      "loss: 0.674747  [32064/60000]\n",
      "loss: 0.789734  [38464/60000]\n",
      "loss: 0.733495  [44864/60000]\n",
      "loss: 0.747153  [51264/60000]\n",
      "loss: 0.686336  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.670068 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.651914  [   64/60000]\n",
      "loss: 0.784361  [ 6464/60000]\n",
      "loss: 0.469537  [12864/60000]\n",
      "loss: 0.735958  [19264/60000]\n",
      "loss: 0.659753  [25664/60000]\n",
      "loss: 0.670088  [32064/60000]\n",
      "loss: 0.747228  [38464/60000]\n",
      "loss: 0.693825  [44864/60000]\n",
      "loss: 0.666039  [51264/60000]\n",
      "loss: 0.660554  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.657986 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.617415  [   64/60000]\n",
      "loss: 0.763765  [ 6464/60000]\n",
      "loss: 0.504906  [12864/60000]\n",
      "loss: 0.758569  [19264/60000]\n",
      "loss: 0.660907  [25664/60000]\n",
      "loss: 0.624445  [32064/60000]\n",
      "loss: 0.737043  [38464/60000]\n",
      "loss: 0.800838  [44864/60000]\n",
      "loss: 0.744829  [51264/60000]\n",
      "loss: 0.709330  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.646483 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.636804  [   64/60000]\n",
      "loss: 0.709468  [ 6464/60000]\n",
      "loss: 0.527087  [12864/60000]\n",
      "loss: 0.723498  [19264/60000]\n",
      "loss: 0.711156  [25664/60000]\n",
      "loss: 0.615480  [32064/60000]\n",
      "loss: 0.670980  [38464/60000]\n",
      "loss: 0.664937  [44864/60000]\n",
      "loss: 0.710959  [51264/60000]\n",
      "loss: 0.607577  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.635748 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.614816  [   64/60000]\n",
      "loss: 0.707628  [ 6464/60000]\n",
      "loss: 0.489302  [12864/60000]\n",
      "loss: 0.701375  [19264/60000]\n",
      "loss: 0.609815  [25664/60000]\n",
      "loss: 0.596263  [32064/60000]\n",
      "loss: 0.744105  [38464/60000]\n",
      "loss: 0.721395  [44864/60000]\n",
      "loss: 0.671495  [51264/60000]\n",
      "loss: 0.600730  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.625912 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.574486  [   64/60000]\n",
      "loss: 0.721622  [ 6464/60000]\n",
      "loss: 0.488595  [12864/60000]\n",
      "loss: 0.728549  [19264/60000]\n",
      "loss: 0.642455  [25664/60000]\n",
      "loss: 0.610294  [32064/60000]\n",
      "loss: 0.735651  [38464/60000]\n",
      "loss: 0.729338  [44864/60000]\n",
      "loss: 0.670417  [51264/60000]\n",
      "loss: 0.646930  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.616754 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.581455  [   64/60000]\n",
      "loss: 0.651348  [ 6464/60000]\n",
      "loss: 0.491175  [12864/60000]\n",
      "loss: 0.707654  [19264/60000]\n",
      "loss: 0.650996  [25664/60000]\n",
      "loss: 0.627171  [32064/60000]\n",
      "loss: 0.666098  [38464/60000]\n",
      "loss: 0.679779  [44864/60000]\n",
      "loss: 0.696203  [51264/60000]\n",
      "loss: 0.619682  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.607846 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.572871  [   64/60000]\n",
      "loss: 0.639697  [ 6464/60000]\n",
      "loss: 0.463474  [12864/60000]\n",
      "loss: 0.712242  [19264/60000]\n",
      "loss: 0.645218  [25664/60000]\n",
      "loss: 0.591073  [32064/60000]\n",
      "loss: 0.673050  [38464/60000]\n",
      "loss: 0.685910  [44864/60000]\n",
      "loss: 0.680410  [51264/60000]\n",
      "loss: 0.665205  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.599832 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.560449  [   64/60000]\n",
      "loss: 0.658762  [ 6464/60000]\n",
      "loss: 0.439639  [12864/60000]\n",
      "loss: 0.711735  [19264/60000]\n",
      "loss: 0.702291  [25664/60000]\n",
      "loss: 0.588156  [32064/60000]\n",
      "loss: 0.640410  [38464/60000]\n",
      "loss: 0.720983  [44864/60000]\n",
      "loss: 0.651035  [51264/60000]\n",
      "loss: 0.613282  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.592366 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.535610  [   64/60000]\n",
      "loss: 0.623020  [ 6464/60000]\n",
      "loss: 0.439348  [12864/60000]\n",
      "loss: 0.661418  [19264/60000]\n",
      "loss: 0.613323  [25664/60000]\n",
      "loss: 0.578198  [32064/60000]\n",
      "loss: 0.646807  [38464/60000]\n",
      "loss: 0.688478  [44864/60000]\n",
      "loss: 0.710046  [51264/60000]\n",
      "loss: 0.609333  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.585287 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.484252  [   64/60000]\n",
      "loss: 0.664570  [ 6464/60000]\n",
      "loss: 0.439155  [12864/60000]\n",
      "loss: 0.660320  [19264/60000]\n",
      "loss: 0.630165  [25664/60000]\n",
      "loss: 0.605465  [32064/60000]\n",
      "loss: 0.604039  [38464/60000]\n",
      "loss: 0.681780  [44864/60000]\n",
      "loss: 0.690952  [51264/60000]\n",
      "loss: 0.579494  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.578767 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.524099  [   64/60000]\n",
      "loss: 0.643074  [ 6464/60000]\n",
      "loss: 0.425485  [12864/60000]\n",
      "loss: 0.682533  [19264/60000]\n",
      "loss: 0.595918  [25664/60000]\n",
      "loss: 0.586165  [32064/60000]\n",
      "loss: 0.649428  [38464/60000]\n",
      "loss: 0.636160  [44864/60000]\n",
      "loss: 0.645136  [51264/60000]\n",
      "loss: 0.569549  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.572591 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.507513  [   64/60000]\n",
      "loss: 0.614488  [ 6464/60000]\n",
      "loss: 0.460531  [12864/60000]\n",
      "loss: 0.696532  [19264/60000]\n",
      "loss: 0.583868  [25664/60000]\n",
      "loss: 0.559413  [32064/60000]\n",
      "loss: 0.619873  [38464/60000]\n",
      "loss: 0.710216  [44864/60000]\n",
      "loss: 0.671713  [51264/60000]\n",
      "loss: 0.600863  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.566845 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.486274  [   64/60000]\n",
      "loss: 0.628098  [ 6464/60000]\n",
      "loss: 0.430219  [12864/60000]\n",
      "loss: 0.708331  [19264/60000]\n",
      "loss: 0.609635  [25664/60000]\n",
      "loss: 0.546494  [32064/60000]\n",
      "loss: 0.601163  [38464/60000]\n",
      "loss: 0.704691  [44864/60000]\n",
      "loss: 0.645793  [51264/60000]\n",
      "loss: 0.565446  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.561256 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.493926  [   64/60000]\n",
      "loss: 0.613942  [ 6464/60000]\n",
      "loss: 0.376692  [12864/60000]\n",
      "loss: 0.695025  [19264/60000]\n",
      "loss: 0.607498  [25664/60000]\n",
      "loss: 0.540468  [32064/60000]\n",
      "loss: 0.607455  [38464/60000]\n",
      "loss: 0.712841  [44864/60000]\n",
      "loss: 0.670727  [51264/60000]\n",
      "loss: 0.545248  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.556191 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.481013  [   64/60000]\n",
      "loss: 0.562349  [ 6464/60000]\n",
      "loss: 0.433377  [12864/60000]\n",
      "loss: 0.666805  [19264/60000]\n",
      "loss: 0.593045  [25664/60000]\n",
      "loss: 0.587128  [32064/60000]\n",
      "loss: 0.606249  [38464/60000]\n",
      "loss: 0.644734  [44864/60000]\n",
      "loss: 0.675255  [51264/60000]\n",
      "loss: 0.568087  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.551073 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.500560  [   64/60000]\n",
      "loss: 0.618631  [ 6464/60000]\n",
      "loss: 0.415513  [12864/60000]\n",
      "loss: 0.620497  [19264/60000]\n",
      "loss: 0.613646  [25664/60000]\n",
      "loss: 0.572566  [32064/60000]\n",
      "loss: 0.607542  [38464/60000]\n",
      "loss: 0.693569  [44864/60000]\n",
      "loss: 0.592101  [51264/60000]\n",
      "loss: 0.557891  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.546736 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.477452  [   64/60000]\n",
      "loss: 0.583678  [ 6464/60000]\n",
      "loss: 0.416824  [12864/60000]\n",
      "loss: 0.682345  [19264/60000]\n",
      "loss: 0.506534  [25664/60000]\n",
      "loss: 0.542897  [32064/60000]\n",
      "loss: 0.558408  [38464/60000]\n",
      "loss: 0.638639  [44864/60000]\n",
      "loss: 0.592590  [51264/60000]\n",
      "loss: 0.564327  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.542367 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.461166  [   64/60000]\n",
      "loss: 0.557703  [ 6464/60000]\n",
      "loss: 0.457119  [12864/60000]\n",
      "loss: 0.638805  [19264/60000]\n",
      "loss: 0.563971  [25664/60000]\n",
      "loss: 0.537696  [32064/60000]\n",
      "loss: 0.573073  [38464/60000]\n",
      "loss: 0.675386  [44864/60000]\n",
      "loss: 0.656254  [51264/60000]\n",
      "loss: 0.567930  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.538181 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.454521  [   64/60000]\n",
      "loss: 0.594309  [ 6464/60000]\n",
      "loss: 0.378403  [12864/60000]\n",
      "loss: 0.674881  [19264/60000]\n",
      "loss: 0.578825  [25664/60000]\n",
      "loss: 0.537637  [32064/60000]\n",
      "loss: 0.556339  [38464/60000]\n",
      "loss: 0.647215  [44864/60000]\n",
      "loss: 0.659704  [51264/60000]\n",
      "loss: 0.509028  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.534549 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.458713  [   64/60000]\n",
      "loss: 0.576849  [ 6464/60000]\n",
      "loss: 0.346030  [12864/60000]\n",
      "loss: 0.628363  [19264/60000]\n",
      "loss: 0.533999  [25664/60000]\n",
      "loss: 0.538977  [32064/60000]\n",
      "loss: 0.510503  [38464/60000]\n",
      "loss: 0.689993  [44864/60000]\n",
      "loss: 0.639134  [51264/60000]\n",
      "loss: 0.532964  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.530647 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.392519  [   64/60000]\n",
      "loss: 0.585487  [ 6464/60000]\n",
      "loss: 0.396170  [12864/60000]\n",
      "loss: 0.606007  [19264/60000]\n",
      "loss: 0.606205  [25664/60000]\n",
      "loss: 0.563885  [32064/60000]\n",
      "loss: 0.546315  [38464/60000]\n",
      "loss: 0.675911  [44864/60000]\n",
      "loss: 0.695619  [51264/60000]\n",
      "loss: 0.553648  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.527046 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.448235  [   64/60000]\n",
      "loss: 0.581293  [ 6464/60000]\n",
      "loss: 0.327347  [12864/60000]\n",
      "loss: 0.620210  [19264/60000]\n",
      "loss: 0.585992  [25664/60000]\n",
      "loss: 0.547809  [32064/60000]\n",
      "loss: 0.594739  [38464/60000]\n",
      "loss: 0.649272  [44864/60000]\n",
      "loss: 0.643038  [51264/60000]\n",
      "loss: 0.509701  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.523682 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.430015  [   64/60000]\n",
      "loss: 0.544287  [ 6464/60000]\n",
      "loss: 0.380895  [12864/60000]\n",
      "loss: 0.608836  [19264/60000]\n",
      "loss: 0.575603  [25664/60000]\n",
      "loss: 0.529118  [32064/60000]\n",
      "loss: 0.580789  [38464/60000]\n",
      "loss: 0.652189  [44864/60000]\n",
      "loss: 0.641808  [51264/60000]\n",
      "loss: 0.553182  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.520629 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.415198  [   64/60000]\n",
      "loss: 0.559401  [ 6464/60000]\n",
      "loss: 0.364302  [12864/60000]\n",
      "loss: 0.608204  [19264/60000]\n",
      "loss: 0.534221  [25664/60000]\n",
      "loss: 0.574648  [32064/60000]\n",
      "loss: 0.527740  [38464/60000]\n",
      "loss: 0.650530  [44864/60000]\n",
      "loss: 0.574861  [51264/60000]\n",
      "loss: 0.498488  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.517426 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.439248  [   64/60000]\n",
      "loss: 0.587995  [ 6464/60000]\n",
      "loss: 0.368372  [12864/60000]\n",
      "loss: 0.585487  [19264/60000]\n",
      "loss: 0.500006  [25664/60000]\n",
      "loss: 0.511805  [32064/60000]\n",
      "loss: 0.573569  [38464/60000]\n",
      "loss: 0.679368  [44864/60000]\n",
      "loss: 0.646687  [51264/60000]\n",
      "loss: 0.528532  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.514529 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.433984  [   64/60000]\n",
      "loss: 0.524339  [ 6464/60000]\n",
      "loss: 0.395251  [12864/60000]\n",
      "loss: 0.581516  [19264/60000]\n",
      "loss: 0.520236  [25664/60000]\n",
      "loss: 0.531539  [32064/60000]\n",
      "loss: 0.515636  [38464/60000]\n",
      "loss: 0.664488  [44864/60000]\n",
      "loss: 0.640781  [51264/60000]\n",
      "loss: 0.504813  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.511770 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.423223  [   64/60000]\n",
      "loss: 0.539973  [ 6464/60000]\n",
      "loss: 0.335490  [12864/60000]\n",
      "loss: 0.616651  [19264/60000]\n",
      "loss: 0.544237  [25664/60000]\n",
      "loss: 0.532550  [32064/60000]\n",
      "loss: 0.560005  [38464/60000]\n",
      "loss: 0.665030  [44864/60000]\n",
      "loss: 0.548322  [51264/60000]\n",
      "loss: 0.487250  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.508736 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.425752  [   64/60000]\n",
      "loss: 0.527092  [ 6464/60000]\n",
      "loss: 0.328840  [12864/60000]\n",
      "loss: 0.614787  [19264/60000]\n",
      "loss: 0.533057  [25664/60000]\n",
      "loss: 0.504855  [32064/60000]\n",
      "loss: 0.560020  [38464/60000]\n",
      "loss: 0.626464  [44864/60000]\n",
      "loss: 0.662893  [51264/60000]\n",
      "loss: 0.500375  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.506320 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.417341  [   64/60000]\n",
      "loss: 0.531774  [ 6464/60000]\n",
      "loss: 0.354004  [12864/60000]\n",
      "loss: 0.627570  [19264/60000]\n",
      "loss: 0.557077  [25664/60000]\n",
      "loss: 0.527289  [32064/60000]\n",
      "loss: 0.531685  [38464/60000]\n",
      "loss: 0.655453  [44864/60000]\n",
      "loss: 0.600211  [51264/60000]\n",
      "loss: 0.490536  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.503571 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.390862  [   64/60000]\n",
      "loss: 0.565676  [ 6464/60000]\n",
      "loss: 0.355830  [12864/60000]\n",
      "loss: 0.600548  [19264/60000]\n",
      "loss: 0.481056  [25664/60000]\n",
      "loss: 0.503059  [32064/60000]\n",
      "loss: 0.508495  [38464/60000]\n",
      "loss: 0.664547  [44864/60000]\n",
      "loss: 0.640757  [51264/60000]\n",
      "loss: 0.477380  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.501201 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.410720  [   64/60000]\n",
      "loss: 0.500934  [ 6464/60000]\n",
      "loss: 0.357153  [12864/60000]\n",
      "loss: 0.595672  [19264/60000]\n",
      "loss: 0.511233  [25664/60000]\n",
      "loss: 0.520689  [32064/60000]\n",
      "loss: 0.541548  [38464/60000]\n",
      "loss: 0.654920  [44864/60000]\n",
      "loss: 0.656826  [51264/60000]\n",
      "loss: 0.487816  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.498908 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.366393  [   64/60000]\n",
      "loss: 0.547639  [ 6464/60000]\n",
      "loss: 0.349391  [12864/60000]\n",
      "loss: 0.600082  [19264/60000]\n",
      "loss: 0.493288  [25664/60000]\n",
      "loss: 0.509587  [32064/60000]\n",
      "loss: 0.521377  [38464/60000]\n",
      "loss: 0.635077  [44864/60000]\n",
      "loss: 0.623595  [51264/60000]\n",
      "loss: 0.504242  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.496542 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.395036  [   64/60000]\n",
      "loss: 0.539723  [ 6464/60000]\n",
      "loss: 0.349148  [12864/60000]\n",
      "loss: 0.540632  [19264/60000]\n",
      "loss: 0.504727  [25664/60000]\n",
      "loss: 0.520554  [32064/60000]\n",
      "loss: 0.491151  [38464/60000]\n",
      "loss: 0.607649  [44864/60000]\n",
      "loss: 0.639295  [51264/60000]\n",
      "loss: 0.441168  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.494327 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model_01.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model_01.pth\")\n",
    "print(\"Saved PyTorch Model State to model_01.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model_01.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_req_dataset = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "out = model(my_req_dataset[0].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.rand((64,1,28,28)).flatten(start_dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
