{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import statsmodels.api as sm\n",
    "from torch.nn import MSELoss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#torch.nn.functional.sigmoid(torch.tensor(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = 5\n",
    "# num_observations = 10000\n",
    "import pandas as pd\n",
    "pd.Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9991, -1.3117, -0.1253,  1.7374, -0.6081]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#binomial_dist = torch.distributions.bernoulli()\n",
    "num_features = 5\n",
    "num_observations = 10000\n",
    "x = torch.rand(size=(num_observations, num_features))\n",
    "weights_original = torch.randn(size=(1,num_features)).float()\n",
    "bias_original = torch.randn(size=(1,)).float()\n",
    "y_linear = x @ weights_original.T + bias_original\n",
    "y_target = torch.bernoulli(torch.sigmoid(y_linear))\n",
    "weights_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                10000\n",
      "Model:                            GLM   Df Residuals:                     9994\n",
      "Model Family:                Binomial   Df Model:                            5\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -6173.8\n",
      "Date:                Wed, 18 Sep 2024   Deviance:                       12348.\n",
      "Time:                        20:28:53   Pearson chi2:                 1.00e+04\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):            0.09955\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2454      0.085      2.872      0.004       0.078       0.413\n",
      "x1            -1.0745      0.075    -14.246      0.000      -1.222      -0.927\n",
      "x2            -1.3519      0.077    -17.639      0.000      -1.502      -1.202\n",
      "x3            -0.1263      0.075     -1.685      0.092      -0.273       0.021\n",
      "x4             1.6846      0.078     21.677      0.000       1.532       1.837\n",
      "x5            -0.5953      0.075     -7.918      0.000      -0.743      -0.448\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "## do logistic regression\n",
    "# Example dataset\n",
    "x_numpy = x.detach().numpy()\n",
    "x_numpy= sm.add_constant(x_numpy)  # Adds a constant (intercept) term\n",
    "y_numpy = y_target.detach().numpy()\n",
    "\n",
    "# Fit logistic regression model using GLM with a logit link\n",
    "glm_model = sm.GLM(y_numpy, x_numpy, family=sm.families.Binomial())\n",
    "result = glm_model.fit()\n",
    "\n",
    "# Print summary of the model\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.24536143 -1.07453786 -1.3518533  -0.12625479  1.68456507 -0.59533207] tensor([[-0.9991, -1.3117, -0.1253,  1.7374, -0.6081]])\n",
      "AUC: 0.6852583886469651\n"
     ]
    }
   ],
   "source": [
    "print(result.params, weights_original)\n",
    "y_pred_prob = result.predict(x_numpy)\n",
    "# Compute AUC using scikit-learn\n",
    "auc = roc_auc_score(y_numpy, y_pred_prob)\n",
    "print(f\"AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 1000000\n",
    "batch_size = 256\n",
    "loss_f = torch.nn.BCELoss()\n",
    "sigmoid_f = torch.nn.Sigmoid()\n",
    "weights_estim_torch = torch.rand(size=(1,num_features), requires_grad=True)\n",
    "bias_estim_torch = torch.rand(size=(1,), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of current batch is: 1.2789621353149414\n",
      "Loss of current batch is: 0.6697881817817688\n",
      "Loss of current batch is: 0.6690037846565247\n",
      "Loss of current batch is: 0.6821731925010681\n",
      "Loss of current batch is: 0.6506352424621582\n",
      "Loss of current batch is: 0.6659315824508667\n",
      "Loss of current batch is: 0.6486377716064453\n",
      "Loss of current batch is: 0.601770281791687\n",
      "Loss of current batch is: 0.6414358019828796\n",
      "Loss of current batch is: 0.6503137946128845\n",
      "Loss of current batch is: 0.6546835899353027\n",
      "Loss of current batch is: 0.6184699535369873\n",
      "Loss of current batch is: 0.6208236813545227\n",
      "Loss of current batch is: 0.6033412218093872\n",
      "Loss of current batch is: 0.610804557800293\n",
      "Loss of current batch is: 0.6160153150558472\n",
      "Loss of current batch is: 0.6269715428352356\n",
      "Loss of current batch is: 0.6285388469696045\n",
      "Loss of current batch is: 0.6071764230728149\n",
      "Loss of current batch is: 0.5790933966636658\n",
      "Loss of current batch is: 0.6262401342391968\n",
      "Loss of current batch is: 0.615852415561676\n",
      "Loss of current batch is: 0.6092727184295654\n",
      "Loss of current batch is: 0.6127269864082336\n",
      "Loss of current batch is: 0.6490849256515503\n",
      "Loss of current batch is: 0.6165072321891785\n",
      "Loss of current batch is: 0.6186938285827637\n",
      "Loss of current batch is: 0.636978030204773\n",
      "Loss of current batch is: 0.625244140625\n",
      "Loss of current batch is: 0.6527782678604126\n",
      "Loss of current batch is: 0.614467978477478\n",
      "Loss of current batch is: 0.6477999091148376\n",
      "Loss of current batch is: 0.6224576830863953\n",
      "Loss of current batch is: 0.6063120365142822\n",
      "Loss of current batch is: 0.628232479095459\n",
      "Loss of current batch is: 0.6679431796073914\n",
      "Loss of current batch is: 0.5899338722229004\n",
      "Loss of current batch is: 0.6278093457221985\n",
      "Loss of current batch is: 0.6118404865264893\n",
      "Loss of current batch is: 0.5976208448410034\n",
      "Loss of current batch is: 0.6096576452255249\n",
      "Loss of current batch is: 0.592960000038147\n",
      "Loss of current batch is: 0.6047347187995911\n",
      "Loss of current batch is: 0.6084006428718567\n",
      "Loss of current batch is: 0.6206812858581543\n",
      "Loss of current batch is: 0.5826691389083862\n",
      "Loss of current batch is: 0.6281602382659912\n",
      "Loss of current batch is: 0.6503713726997375\n",
      "Loss of current batch is: 0.6380197405815125\n",
      "Loss of current batch is: 0.6232572793960571\n",
      "Loss of current batch is: 0.6269962787628174\n",
      "Loss of current batch is: 0.645355224609375\n",
      "Loss of current batch is: 0.6059073209762573\n",
      "Loss of current batch is: 0.6434156894683838\n",
      "Loss of current batch is: 0.6220235824584961\n",
      "Loss of current batch is: 0.6019523739814758\n",
      "Loss of current batch is: 0.6338269114494324\n",
      "Loss of current batch is: 0.6100412011146545\n",
      "Loss of current batch is: 0.6008683443069458\n",
      "Loss of current batch is: 0.5848070383071899\n",
      "Loss of current batch is: 0.6026619672775269\n",
      "Loss of current batch is: 0.6561192274093628\n",
      "Loss of current batch is: 0.6219531297683716\n",
      "Loss of current batch is: 0.6003234386444092\n",
      "Loss of current batch is: 0.6346153020858765\n",
      "Loss of current batch is: 0.6044821739196777\n",
      "Loss of current batch is: 0.6355020999908447\n",
      "Loss of current batch is: 0.5925455093383789\n",
      "Loss of current batch is: 0.6397867798805237\n",
      "Loss of current batch is: 0.5686829090118408\n",
      "Loss of current batch is: 0.6328207850456238\n",
      "Loss of current batch is: 0.5769027471542358\n",
      "Loss of current batch is: 0.6381181478500366\n",
      "Loss of current batch is: 0.603187084197998\n",
      "Loss of current batch is: 0.6096600294113159\n",
      "Loss of current batch is: 0.5961674451828003\n",
      "Loss of current batch is: 0.650017499923706\n",
      "Loss of current batch is: 0.6351253390312195\n",
      "Loss of current batch is: 0.6248483061790466\n",
      "Loss of current batch is: 0.6085205078125\n",
      "Loss of current batch is: 0.5894564986228943\n",
      "Loss of current batch is: 0.647744357585907\n",
      "Loss of current batch is: 0.6026172637939453\n",
      "Loss of current batch is: 0.618384063243866\n",
      "Loss of current batch is: 0.6003490686416626\n",
      "Loss of current batch is: 0.6601663827896118\n",
      "Loss of current batch is: 0.5717477202415466\n",
      "Loss of current batch is: 0.6034678816795349\n",
      "Loss of current batch is: 0.5831832885742188\n",
      "Loss of current batch is: 0.646483838558197\n",
      "Loss of current batch is: 0.5821182131767273\n",
      "Loss of current batch is: 0.6291908025741577\n",
      "Loss of current batch is: 0.602170467376709\n",
      "Loss of current batch is: 0.647102415561676\n",
      "Loss of current batch is: 0.5936934947967529\n",
      "Loss of current batch is: 0.5885536074638367\n",
      "Loss of current batch is: 0.6194128394126892\n",
      "Loss of current batch is: 0.6397403478622437\n",
      "Loss of current batch is: 0.5627378821372986\n",
      "Loss of current batch is: 0.580761194229126\n",
      "Loss of current batch is: 0.5936892628669739\n",
      "Loss of current batch is: 0.6165593862533569\n",
      "Loss of current batch is: 0.624728262424469\n",
      "Loss of current batch is: 0.6261072158813477\n",
      "Loss of current batch is: 0.6046663522720337\n",
      "Loss of current batch is: 0.6352108120918274\n",
      "Loss of current batch is: 0.6133340001106262\n",
      "Loss of current batch is: 0.594985842704773\n",
      "Loss of current batch is: 0.622026264667511\n",
      "Loss of current batch is: 0.646804928779602\n",
      "Loss of current batch is: 0.5950855016708374\n",
      "Loss of current batch is: 0.6442158818244934\n",
      "Loss of current batch is: 0.6778879165649414\n",
      "Loss of current batch is: 0.6181148290634155\n",
      "Loss of current batch is: 0.6321283578872681\n",
      "Loss of current batch is: 0.6290414333343506\n",
      "Loss of current batch is: 0.6310086250305176\n",
      "Loss of current batch is: 0.6217061281204224\n",
      "Loss of current batch is: 0.6077395677566528\n",
      "Loss of current batch is: 0.6007087826728821\n",
      "Loss of current batch is: 0.5978794693946838\n",
      "Loss of current batch is: 0.6113102436065674\n",
      "Loss of current batch is: 0.602526068687439\n",
      "Loss of current batch is: 0.5982918739318848\n",
      "Loss of current batch is: 0.6188399791717529\n",
      "Loss of current batch is: 0.6226655840873718\n",
      "Loss of current batch is: 0.6319653987884521\n",
      "Loss of current batch is: 0.6041226983070374\n",
      "Loss of current batch is: 0.6020346879959106\n",
      "Loss of current batch is: 0.6400437355041504\n",
      "Loss of current batch is: 0.608046293258667\n",
      "Loss of current batch is: 0.6071367263793945\n",
      "Loss of current batch is: 0.6171714067459106\n",
      "Loss of current batch is: 0.6309204697608948\n",
      "Loss of current batch is: 0.5976079702377319\n",
      "Loss of current batch is: 0.6020951271057129\n",
      "Loss of current batch is: 0.6301134824752808\n",
      "Loss of current batch is: 0.5841430425643921\n",
      "Loss of current batch is: 0.6001396179199219\n",
      "Loss of current batch is: 0.5918604731559753\n",
      "Loss of current batch is: 0.5815305709838867\n",
      "Loss of current batch is: 0.5959503650665283\n",
      "Loss of current batch is: 0.6480330228805542\n",
      "Loss of current batch is: 0.62987220287323\n",
      "Loss of current batch is: 0.593192994594574\n",
      "Loss of current batch is: 0.6570430994033813\n",
      "Loss of current batch is: 0.626369059085846\n",
      "Loss of current batch is: 0.6044059991836548\n",
      "Loss of current batch is: 0.648221492767334\n",
      "Loss of current batch is: 0.6395144462585449\n",
      "Loss of current batch is: 0.6380869746208191\n",
      "Loss of current batch is: 0.6198291778564453\n",
      "Loss of current batch is: 0.6336309909820557\n",
      "Loss of current batch is: 0.633424699306488\n",
      "Loss of current batch is: 0.6252987384796143\n",
      "Loss of current batch is: 0.5877468585968018\n",
      "Loss of current batch is: 0.6265811920166016\n",
      "Loss of current batch is: 0.6816970705986023\n",
      "Loss of current batch is: 0.6132646799087524\n",
      "Loss of current batch is: 0.6290513277053833\n",
      "Loss of current batch is: 0.6254482865333557\n",
      "Loss of current batch is: 0.6342676281929016\n",
      "Loss of current batch is: 0.5760973691940308\n",
      "Loss of current batch is: 0.610472559928894\n",
      "Loss of current batch is: 0.6308445334434509\n",
      "Loss of current batch is: 0.6298465728759766\n",
      "Loss of current batch is: 0.6549098491668701\n",
      "Loss of current batch is: 0.6174701452255249\n",
      "Loss of current batch is: 0.6337456107139587\n",
      "Loss of current batch is: 0.6400384902954102\n",
      "Loss of current batch is: 0.6161624789237976\n",
      "Loss of current batch is: 0.6514387726783752\n",
      "Loss of current batch is: 0.6123833656311035\n",
      "Loss of current batch is: 0.6336168050765991\n",
      "Loss of current batch is: 0.6282326579093933\n",
      "Loss of current batch is: 0.618220329284668\n",
      "Loss of current batch is: 0.6309596300125122\n",
      "Loss of current batch is: 0.6342568397521973\n",
      "Loss of current batch is: 0.5990867018699646\n",
      "Loss of current batch is: 0.6320043206214905\n",
      "Loss of current batch is: 0.6703376770019531\n",
      "Loss of current batch is: 0.6090261936187744\n",
      "Loss of current batch is: 0.5931237936019897\n",
      "Loss of current batch is: 0.6296219229698181\n",
      "Loss of current batch is: 0.5984010696411133\n",
      "Loss of current batch is: 0.6095016002655029\n",
      "Loss of current batch is: 0.642483115196228\n",
      "Loss of current batch is: 0.6169372200965881\n",
      "Loss of current batch is: 0.5924022197723389\n",
      "Loss of current batch is: 0.6329363584518433\n",
      "Loss of current batch is: 0.6012749671936035\n",
      "Loss of current batch is: 0.6132415533065796\n",
      "Loss of current batch is: 0.6262510418891907\n",
      "Loss of current batch is: 0.6140518188476562\n",
      "Loss of current batch is: 0.63129061460495\n",
      "Loss of current batch is: 0.5979004502296448\n",
      "Loss of current batch is: 0.6467916965484619\n",
      "Loss of current batch is: 0.5825523138046265\n",
      "Loss of current batch is: 0.6710480451583862\n",
      "Loss of current batch is: 0.6420444250106812\n"
     ]
    }
   ],
   "source": [
    "for cur_epoch in range(epochs):\n",
    "    cur_batch_index = torch.randint(low=0,high=x.shape[0], size=(batch_size,))\n",
    "    cur_batch_x = x[cur_batch_index,]\n",
    "    cur_batch_y = y_target[cur_batch_index,]\n",
    "    cur_batch_pred = torch.sigmoid( cur_batch_x @ weights_estim_torch.T + bias_estim_torch)\n",
    "    cur_batch_loss = loss_f(cur_batch_pred, cur_batch_y)\n",
    "    if cur_epoch % 5000 == 0:\n",
    "        print(f\"Loss of current batch is: {cur_batch_loss.item()}\")\n",
    "    cur_batch_loss.backward()\n",
    "    with torch.no_grad():\n",
    "        weights_estim_torch -= lr * weights_estim_torch.grad\n",
    "        bias_estim_torch -= lr* bias_estim_torch.grad\n",
    "    ## avoid gradient accumaltion\n",
    "    weights_estim_torch.grad.zero_()\n",
    "    bias_estim_torch.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0763, -1.3520, -0.1244,  1.6834, -0.5995]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.rand(size=(4,2)) + torch.rand(size=(1,))\n",
    "weights_estim_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_estim_torch\n",
    "#tensor([[ 1.6484, -1.2829, -0.2156,  1.5310, -1.4347]])\n",
    "#tensor([[-0.9991, -1.3117, -0.1253,  1.7374, -0.6081]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_torch = roc_auc_score(y_target.numpy(), torch.sigmoid( x @ weights_estim_torch.T + bias_estim_torch).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6852636733888584)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
